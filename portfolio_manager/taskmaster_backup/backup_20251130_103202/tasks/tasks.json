{
  "master": {
    "tasks": [
      {
        "id": "1",
        "title": "Implement CrashRecoveryManager State Loading",
        "description": "Restore application state from PostgreSQL on startup to enable crash recovery",
        "details": "**Implementation Complete:**\n- Created CrashRecoveryManager class (live/recovery.py)\n- Data fetching with retry logic (exponential backoff: 1s, 2s, 4s)\n- PortfolioStateManager reconstruction\n- LiveTradingEngine reconstruction\n- State consistency validation (risk, margin with 0.01‚Çπ tolerance)\n- Error handling with 3 error codes (DB_UNAVAILABLE, DATA_CORRUPT, VALIDATION_FAILED)\n- HA system integration (status updates: recovering ‚Üí active/crashed)\n\n**Integration Complete:**\n- Removed old recovery from LiveTradingEngine.__init__\n- Integrated CrashRecoveryManager into portfolio_manager.py\n- Added --redis-config argument\n- Excellent error handling with fail-safe defaults\n\n**Status:** Implementation and integration complete. Requires integration test fixes before merge.",
        "testStrategy": "Unit tests: 15 test cases in tests/unit/test_crash_recovery.py\nIntegration tests: Require updates to test_persistence.py\nManual testing: 4 scenarios (normal recovery, DB unavailable, corruption, HA recovery)",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Fix integration tests in test_persistence.py",
            "description": "Update TestRecoveryFlow tests to use explicit CrashRecoveryManager.load_state() calls",
            "details": "**CRITICAL BLOCKER** - Tests currently fail because they expect auto-recovery in LiveTradingEngine.__init__\n\n**Tests to fix:**\n1. test_recovery_loads_positions (line 358)\n2. test_recovery_allows_continued_trading (line 406)\n\n**Changes needed:**\n- Import CrashRecoveryManager\n- After creating engine2, call recovery_manager.load_state()\n- Assert success is True\n- Verify positions are loaded\n\n**Estimated time:** 30 minutes\n\n**File:** tests/integration/test_persistence.py",
            "status": "pending",
            "dependencies": [],
            "parentTaskId": 1,
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Run integration tests and verify all pass",
            "description": "Execute pytest on integration tests to verify fixes work correctly",
            "details": "**Commands to run:**\n```bash\n# Run specific test class\npytest tests/integration/test_persistence.py::TestRecoveryFlow -v\n\n# Run all integration tests\npytest tests/integration/ -v\n\n# Run with coverage\npytest tests/integration/test_persistence.py --cov=live.recovery --cov-report=term\n```\n\n**Expected results:**\n- All tests in TestRecoveryFlow pass ‚úÖ\n- No test failures\n- Coverage report shows recovery code is tested\n\n**Estimated time:** 5 minutes\n\n**Dependencies:** Subtask 1.1 must be complete",
            "status": "pending",
            "dependencies": [
              "1.1"
            ],
            "parentTaskId": 1,
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Create comprehensive integration test file",
            "description": "Create test_crash_recovery_integration.py for full recovery flow testing",
            "details": "**New file:** tests/integration/test_crash_recovery_integration.py\n\n**Test cases to include:**\n1. test_full_recovery_with_signal_processing\n   - Create engine, process signal, crash, recover, process more signals\n2. test_recovery_with_coordinator_integration\n   - Test HA status updates during recovery\n3. test_recovery_validation_failure\n   - Corrupt data in DB, verify recovery fails with VALIDATION_FAILED\n4. test_recovery_data_corruption\n   - Invalid data types, verify recovery fails with DATA_CORRUPT\n5. test_recovery_db_unavailable\n   - Stop database, verify recovery handles gracefully\n6. test_recovery_with_multiple_positions\n   - Test recovery with 3-5 positions, verify all loaded correctly\n\n**Estimated time:** 2 hours\n\n**Priority:** HIGH",
            "status": "pending",
            "dependencies": [],
            "parentTaskId": 1,
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Manual testing - Scenario 1: Normal Recovery",
            "description": "Test normal crash recovery flow with real application",
            "details": "**Test procedure:**\n1. Start application with database\n   ```bash\n   python portfolio_manager.py live --db-config database_config.json --broker zerodha --api-key TEST\n   ```\n2. Send BASE_ENTRY signal via webhook\n3. Verify position created and saved to database\n4. Kill application (Ctrl+C)\n5. Restart application\n6. Verify logs show:\n   - \"Fetched 1 open positions from database\"\n   - \"‚úÖ Crash recovery completed successfully - state restored\"\n7. Send PYRAMID signal\n8. Verify pyramid executes successfully\n\n**Expected result:** Recovery works, pyramid builds on recovered position\n\n**Estimated time:** 15 minutes",
            "status": "pending",
            "dependencies": [],
            "parentTaskId": 1,
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Manual testing - Scenario 2: Database Unavailable",
            "description": "Test recovery behavior when PostgreSQL is unavailable",
            "details": "**Test procedure:**\n1. Stop PostgreSQL\n   ```bash\n   sudo service postgresql stop\n   # OR on macOS: brew services stop postgresql\n   ```\n2. Start application\n   ```bash\n   python portfolio_manager.py live --db-config database_config.json --broker zerodha --api-key TEST\n   ```\n3. Verify logs show:\n   - \"Failed to fetch state data after 3 attempts\"\n   - \"Database unavailable - starting with empty state\"\n   - \"‚ö†Ô∏è  WARNING: If positions exist in database, they will not be tracked\"\n4. Verify application STARTS (does not halt)\n5. Restart PostgreSQL\n6. Restart application\n7. Verify normal recovery works\n\n**Expected result:** Application starts with warnings, continues operation\n\n**Estimated time:** 10 minutes",
            "status": "pending",
            "dependencies": [],
            "parentTaskId": 1,
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Manual testing - Scenario 3: State Corruption",
            "description": "Test recovery behavior when database has corrupted state",
            "details": "**Test procedure:**\n1. Start application, create position\n2. Manually corrupt data in database:\n   ```sql\n   UPDATE portfolio_state SET total_risk_amount = 999999.99;\n   ```\n3. Restart application\n4. Verify logs show:\n   - \"Risk amount mismatch: DB=999999.99, Calculated=100000.00\"\n   - \"üö® CRITICAL: State corruption detected - HALTING STARTUP\"\n5. Verify application EXITS with code 1\n6. Fix corruption:\n   ```sql\n   UPDATE portfolio_state SET total_risk_amount = 100000.00;\n   ```\n7. Restart application\n8. Verify normal recovery works\n\n**Expected result:** Application halts on corruption, prevents financial loss\n\n**Estimated time:** 15 minutes",
            "status": "pending",
            "dependencies": [],
            "parentTaskId": 1,
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Manual testing - Scenario 4: HA Recovery",
            "description": "Test multi-instance recovery with Redis coordinator",
            "details": "**Test procedure:**\n1. Start Redis server\n2. Terminal 1: Start instance A\n   ```bash\n   python portfolio_manager.py live --db-config db.json --redis-config redis.json\n   ```\n3. Verify instance A becomes leader\n4. Terminal 2: Start instance B\n   ```bash\n   python portfolio_manager.py live --db-config db.json --redis-config redis.json\n   ```\n5. Verify instance B becomes follower\n6. Send signal to instance A, verify position created\n7. Kill instance A (Ctrl+C)\n8. Verify instance B becomes leader\n9. Restart instance A\n10. Verify logs show:\n    - \"Instance status set to 'recovering' in HA system\"\n    - \"‚úÖ Crash recovery completed successfully\"\n    - \"Instance status set to 'active' in HA system\"\n11. Verify instance A is follower, instance B is leader\n12. Verify both instances have same state\n\n**Expected result:** Multi-instance recovery works, no split-brain\n\n**Estimated time:** 20 minutes",
            "status": "pending",
            "dependencies": [],
            "parentTaskId": 1,
            "parentId": "undefined"
          },
          {
            "id": 8,
            "title": "Performance testing - Recovery with 10+ positions",
            "description": "Test recovery performance with larger position count",
            "details": "**Test procedure:**\n1. Create test script to populate database with 10-15 positions\n2. Measure recovery time:\n   ```python\n   import time\n   start = time.time()\n   success, error_code = recovery_manager.load_state(...)\n   duration = time.time() - start\n   print(f\"Recovery took {duration:.2f} seconds\")\n   ```\n3. Verify recovery completes in < 5 seconds\n4. Test with 20, 30, 50 positions\n5. Plot recovery time vs. position count\n\n**Target performance:**\n- 10 positions: < 2 seconds\n- 20 positions: < 3 seconds\n- 50 positions: < 5 seconds\n\n**Optimization if needed:**\n- Batch database queries\n- Parallel position loading\n- Optimize validation logic\n\n**Estimated time:** 1 hour",
            "status": "pending",
            "dependencies": [],
            "parentTaskId": 1,
            "parentId": "undefined"
          },
          {
            "id": 9,
            "title": "Update ARCHITECTURE.md with recovery section",
            "description": "Document CrashRecoveryManager in architecture documentation",
            "details": "**File:** ARCHITECTURE.md\n\n**Content to add:**\n1. **Crash Recovery Architecture**\n   - Overview of CrashRecoveryManager\n   - When recovery happens (startup sequence)\n   - What state is recovered (positions, portfolio, pyramiding)\n\n2. **Recovery Flow Diagram**\n   - State diagram showing fetch ‚Üí reconstruct ‚Üí validate\n\n3. **Error Handling**\n   - Explanation of 3 error codes\n   - Decision tree for failure modes\n   - Fail-safe behavior\n\n4. **HA Integration**\n   - Instance status during recovery\n   - Multi-instance recovery safety\n\n5. **Consistency Validation**\n   - What is validated (risk, margin)\n   - Epsilon tolerance (0.01‚Çπ)\n   - Why validation is critical\n\n**Estimated time:** 1 hour",
            "status": "pending",
            "dependencies": [],
            "parentTaskId": 1,
            "parentId": "undefined"
          },
          {
            "id": 10,
            "title": "Create RUNBOOK.md for recovery failures",
            "description": "Document procedures for handling recovery failure scenarios",
            "details": "**New file:** RUNBOOK.md\n\n**Sections to include:**\n\n1. **Recovery Failure Scenarios**\n   - VALIDATION_FAILED: What to do\n   - DATA_CORRUPT: How to investigate\n   - DB_UNAVAILABLE: When to wait vs. restart\n\n2. **Troubleshooting Guide**\n   - How to check database state\n   - SQL queries for debugging\n   - Log file locations\n   - Common error messages\n\n3. **Emergency Procedures**\n   - Manual state correction\n   - Database rollback procedures\n   - When to delete corrupted data\n   - How to restore from backup\n\n4. **Monitoring Checklist**\n   - What to watch during recovery\n   - Alert thresholds\n   - When to escalate\n\n5. **Recovery Metrics**\n   - Success rate target (>99%)\n   - Duration target (<5 seconds)\n   - When to investigate slow recovery\n\n**Estimated time:** 2 hours",
            "status": "pending",
            "dependencies": [],
            "parentTaskId": 1,
            "parentId": "undefined"
          },
          {
            "id": 11,
            "title": "Add recovery metrics to monitoring dashboard",
            "description": "Create monitoring panel for crash recovery metrics",
            "details": "**Metrics to track:**\n\n1. **Recovery Success Rate**\n   - Total recoveries attempted\n   - Successful recoveries\n   - Failed recoveries (by error code)\n\n2. **Recovery Duration**\n   - Average recovery time\n   - 95th percentile recovery time\n   - Max recovery time (alert if >10s)\n\n3. **Recovery Errors**\n   - VALIDATION_FAILED count (alert immediately)\n   - DATA_CORRUPT count (alert immediately)\n   - DB_UNAVAILABLE count (alert after 3 occurrences)\n\n4. **State Statistics**\n   - Number of positions recovered\n   - Total equity recovered\n   - Pyramiding state count\n\n5. **HA Status**\n   - Instance status during recovery\n   - Recovery time by instance\n\n**Implementation:**\n- Add metrics collection to CrashRecoveryManager\n- Export to Prometheus/StatsD\n- Create Grafana dashboard\n- Configure alerts\n\n**Estimated time:** 3 hours",
            "status": "pending",
            "dependencies": [],
            "parentTaskId": 1,
            "parentId": "undefined"
          },
          {
            "id": 12,
            "title": "Add alerting for DB_UNAVAILABLE events",
            "description": "Configure alerts when database is unavailable during recovery",
            "details": "**Alert configuration:**\n\n1. **Alert Conditions**\n   - Trigger: DB_UNAVAILABLE error during recovery\n   - Severity: WARNING (not CRITICAL, allows manual intervention)\n   - Threshold: Alert after 2 consecutive occurrences within 10 minutes\n\n2. **Alert Channels**\n   - PagerDuty: Page on-call engineer\n   - Slack: Post to #alerts channel\n   - Email: Send to ops team\n\n3. **Alert Message**\n   ```\n   üö® Portfolio Manager - Database Unavailable During Recovery\n   Instance: {instance_id}\n   Time: {timestamp}\n   Retry attempts: 3\n   Status: Application started with empty state\n   \n   Action Required:\n   1. Verify PostgreSQL is running\n   2. Check database connectivity\n   3. Review database logs\n   4. Restart application after DB is back online\n   ```\n\n4. **Runbook Link**\n   - Include link to RUNBOOK.md section on DB_UNAVAILABLE\n\n**Estimated time:** 1 hour",
            "status": "pending",
            "dependencies": [],
            "parentTaskId": 1,
            "parentId": "undefined"
          },
          {
            "id": 13,
            "title": "Plan deployment strategy",
            "description": "Create deployment plan with rollback procedures",
            "details": "**Deployment Plan:**\n\n1. **Pre-Deployment Checklist**\n   - [ ] All tests pass (unit + integration)\n   - [ ] Manual testing completed (4 scenarios)\n   - [ ] Performance testing completed\n   - [ ] Documentation updated\n   - [ ] Monitoring/alerting configured\n   - [ ] Database backup created\n\n2. **Deployment Strategy**\n   - **Type:** Rolling deployment\n   - **Instances:** Deploy to 1 instance first (canary)\n   - **Monitoring:** Watch for 30 minutes\n   - **Verification:** Send test signals, verify recovery works\n   - **Rollout:** Deploy to remaining instances\n\n3. **Rollback Plan**\n   - **Trigger:** Critical errors, recovery failures\n   - **Procedure:**\n     1. Revert code to previous version\n     2. Restart all instances\n     3. Verify old recovery works\n     4. Review logs\n   - **RTO:** < 5 minutes\n   - **RPO:** 0 (state in database)\n\n4. **Post-Deployment Validation**\n   - Verify recovery metrics in dashboard\n   - Check for any alerts\n   - Review logs for errors\n   - Test recovery on each instance\n\n**Estimated time:** 1 hour",
            "status": "pending",
            "dependencies": [],
            "parentTaskId": 1,
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": "2",
        "title": "Phase 1: Update Position Model",
        "description": "Add is_base_position field to Position dataclass for pyramid tracking",
        "details": "**Status:** ‚úÖ Complete\n\n**Changes Made:**\n- Added `is_base_position: bool = False` field to Position dataclass in core/models.py\n- Field properly integrated in serialization/deserialization\n- Set to TRUE for base entries, FALSE for pyramid entries\n\n**File:** core/models.py (line ~205)\n\n**Verification:** All existing tests pass with new field",
        "testStrategy": "Unit tests: Existing test suite validates no regressions\nIntegration tests: Position serialization verified in database tests",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-11-30T03:24:11.973Z"
      },
      {
        "id": "3",
        "title": "Phase 1: Create Database Schema",
        "description": "Create PostgreSQL schema with 5 tables for state persistence",
        "details": "**Status:** ‚úÖ Complete\n\n**Files Created:**\n- migrations/001_initial_schema.sql (200+ lines)\n- migrations/__init__.py\n\n**Tables Created:**\n1. portfolio_positions - All position data (36 columns, 5 indexes)\n2. portfolio_state - Single-row portfolio metrics\n3. pyramiding_state - Per-instrument pyramiding metadata\n4. signal_log - Signal audit trail with fingerprint deduplication\n5. instance_metadata - HA instance tracking\n\n**Indexes:**\n- idx_instrument_status\n- idx_status\n- idx_created_at\n- idx_instrument_entry\n- idx_rollover_status\n- idx_fingerprint\n- idx_processed_at\n- idx_instrument_timestamp\n\n**Constraints:**\n- status CHECK IN ('open', 'closed', 'partial')\n- rollover_status CHECK IN ('none', 'pending', 'in_progress', 'rolled', 'failed')\n- portfolio_state single row CHECK (id = 1)\n\n**Verification:**\n```bash\npsql -U pm_user -d portfolio_manager -f migrations/001_initial_schema.sql\npsql -U pm_user -d portfolio_manager -c \"\\dt\"\n```",
        "testStrategy": "Manual verification: Database tables created successfully\nSchema validation: All constraints and indexes verified",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-11-30T03:24:12.110Z"
      },
      {
        "id": "4",
        "title": "Phase 1: Implement DatabaseStateManager",
        "description": "Complete database persistence layer with connection pooling, caching, and transactions",
        "details": "**Status:** ‚úÖ Complete\n\n**File Created:**\n- core/db_state_manager.py (500+ lines)\n\n**Features Implemented:**\n- Connection pooling (psycopg2.pool.ThreadedConnectionPool)\n- Retry logic with exponential backoff (1s, 2s, 4s)\n- Write-through L1 caching (positions, portfolio state)\n- Transaction management with automatic rollback\n- Optimistic locking (version field)\n\n**Methods Implemented:**\n- Position operations: save_position(), get_position(), get_all_open_positions()\n- Portfolio state: save_portfolio_state(), get_portfolio_state()\n- Pyramiding state: save_pyramiding_state(), get_pyramiding_state()\n- Signal deduplication: check_duplicate_signal(), log_signal()\n- Helper methods: _position_to_dict(), _dict_to_position()\n\n**Key Features:**\n- Automatic connection retry on failure\n- Transaction retry on connection loss\n- Cache invalidation on updates\n- Comprehensive error handling with logging\n\n**Verification:**\n```bash\npython -m py_compile core/db_state_manager.py\npython -c \"from core.db_state_manager import DatabaseStateManager; print('OK')\"\n```",
        "testStrategy": "Unit tests: 20+ tests in tests/unit/test_db_state_manager.py\nCoverage: >90% target\nIntegration tests: Full CRUD operations verified",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-11-30T03:24:12.295Z"
      },
      {
        "id": "5",
        "title": "Phase 1: Create Unit Tests for DatabaseStateManager",
        "description": "Comprehensive unit test suite for database persistence layer",
        "details": "**Status:** ‚úÖ Complete\n\n**File Created:**\n- tests/unit/test_db_state_manager.py (400+ lines, 20+ tests)\n\n**Test Coverage:**\n- Connection management (pool init, retry, transaction rollback)\n- Position CRUD (insert, update, optimistic locking, cache behavior)\n- Portfolio state (save, get, version increment)\n- Pyramiding state (save, get, nullable base_position_id)\n- Signal deduplication (exists check, log, duplicate detection)\n- Serialization (is_base_position field, NULL handling, type conversions)\n\n**Test Classes:**\n- TestDatabaseConnectionManagement (3 tests)\n- TestPositionCRUD (7 tests)\n- TestPortfolioState (3 tests)\n- TestPyramidingState (3 tests)\n- TestSignalDeduplication (4 tests)\n\n**Results:**\n- ‚úÖ 20+ tests passing\n- ‚úÖ >90% code coverage achieved\n- ‚úÖ All edge cases covered\n\n**Verification:**\n```bash\npytest tests/unit/test_db_state_manager.py -v --cov=core.db_state_manager\n```",
        "testStrategy": "Unit tests: Self-testing\nCoverage verification: pytest --cov-report=html",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-11-30T03:24:12.474Z"
      },
      {
        "id": "6",
        "title": "Phase 1: Integrate with PortfolioStateManager",
        "description": "Add database hooks for closed_equity persistence",
        "details": "**Status:** ‚úÖ Complete\n\n**File Modified:**\n- core/portfolio_state.py\n\n**Changes Made:**\n- Added `db_manager: Optional[DatabaseStateManager] = None` parameter to __init__\n- Load closed_equity from database on initialization (if db_manager provided)\n- Save closed_equity to database when positions close (in close_position method)\n- Backward compatible - works without database\n\n**Integration Points:**\n- Load state on startup: `closed_equity = db_manager.get_portfolio_state()['closed_equity']`\n- Save on position close: `db_manager.save_portfolio_state(portfolio_state)`\n\n**Verification:**\n```bash\npytest tests/unit/test_portfolio_state.py -v\npytest tests/ -v  # Ensure no regressions\n```",
        "testStrategy": "Unit tests: Existing test suite validates no regressions\nIntegration tests: Database persistence verified in integration tests",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-11-30T03:24:12.696Z"
      },
      {
        "id": "7",
        "title": "Phase 1: Integrate with LiveTradingEngine",
        "description": "Add persistence calls for all signal processing and state recovery on startup",
        "details": "**Status:** ‚úÖ Complete\n\n**File Modified:**\n- live/engine.py\n\n**Changes Made:**\n\n1. **Initialization:**\n   - Added `db_manager: Optional[DatabaseStateManager] = None` parameter\n   - Load state from database on startup if db_manager provided\n\n2. **State Recovery on Startup:**\n   - Load all open positions: `self.positions = db_manager.get_all_open_positions()`\n   - Load pyramiding state: `self.last_pyramid_price`, `self.base_positions`\n   - Load portfolio state: `closed_equity`\n\n3. **Persistence Calls:**\n   - **_handle_base_entry_live:** Save position, update pyramiding state, set is_base_position=True\n   - **_handle_pyramid_live:** Save position, update pyramiding state, set is_base_position=False\n   - **_handle_exit_live:** Save closed position (status='closed'), update portfolio state\n\n4. **is_base_position Tracking:**\n   - Set to TRUE for base entries\n   - Set to FALSE for pyramid entries\n\n**Verification:**\n```bash\npytest tests/integration/ -v\n# Manual test: Start engine, process signal, verify database\n```",
        "testStrategy": "Integration tests: Full signal flow verified in test_persistence.py\nManual testing: Signal processing with database verification",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-11-30T03:24:12.890Z"
      },
      {
        "id": "8",
        "title": "Phase 1: Update Main Application",
        "description": "Add database initialization and CLI arguments to portfolio_manager.py",
        "details": "**Status:** ‚úÖ Complete\n\n**File Modified:**\n- portfolio_manager.py\n\n**Changes Made:**\n\n1. **Database Initialization:**\n   - Import DatabaseStateManager\n   - Load database config from database_config.json or environment\n   - Initialize DatabaseStateManager in run_live() function\n   - Pass db_manager to LiveTradingEngine and PortfolioStateManager\n\n2. **Command-Line Arguments:**\n   - `--db-config`: Path to database config JSON file\n   - `--db-env`: Environment name (local/production)\n\n3. **Database Status Endpoint:**\n   - `/db/status` endpoint to check database connection health\n   - Returns connection status, table counts, last update time\n\n4. **Graceful Fallback:**\n   - If database unavailable, continue with in-memory only\n   - Log warnings when database is not available\n\n**Verification:**\n```bash\npython portfolio_manager.py live --db-config database_config.json --db-env local\n# Check /db/status endpoint\ncurl http://localhost:5000/db/status\n```",
        "testStrategy": "Manual testing: Application startup with database\nEndpoint testing: /db/status health check\nFallback testing: Start without database config",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-11-30T03:24:13.079Z"
      },
      {
        "id": "9",
        "title": "Phase 1: Create Integration Tests",
        "description": "End-to-end integration tests for signal ‚Üí database ‚Üí recovery flow",
        "details": "**Status:** ‚úÖ Complete\n\n**File Created:**\n- tests/integration/test_persistence.py (300+ lines, 6+ tests)\n\n**Test Coverage:**\n\n1. **Signal ‚Üí Database ‚Üí Recovery:**\n   - Process BASE_ENTRY signal\n   - Verify position in database\n   - Restart engine\n   - Verify position loaded from database\n   - Verify state matches exactly\n\n2. **Full Signal Sequence:**\n   - BASE_ENTRY ‚Üí PYRAMID ‚Üí EXIT\n   - Verify all positions persisted\n   - Verify portfolio state updated\n   - Verify pyramiding state updated\n\n3. **Crash Recovery:**\n   - Create position\n   - Simulate crash (kill process)\n   - Restart engine\n   - Verify position recovered\n   - Verify can continue trading\n\n4. **Concurrent Updates:**\n   - Update position stop from two threads\n   - Verify optimistic locking prevents conflicts\n   - Verify version increments correctly\n\n**Test Classes:**\n- TestDatabasePersistence (2 tests)\n- TestRecoveryFlow (2 tests)\n- TestConcurrentUpdates (2 tests)\n\n**Results:**\n- ‚úÖ 6+ integration tests passing\n- ‚úÖ Full end-to-end flow verified\n- ‚úÖ Recovery scenarios validated\n\n**Verification:**\n```bash\npytest tests/integration/test_persistence.py -v\n```",
        "testStrategy": "Integration tests: Self-testing\nEnd-to-end validation: Full signal processing flow",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-11-30T03:24:13.269Z"
      },
      {
        "id": "10",
        "title": "Phase 1: Documentation",
        "description": "Complete documentation for database setup and usage",
        "details": "**Status:** ‚úÖ Complete\n\n**Files Created:**\n- DATABASE_SETUP.md (400+ lines) - Complete setup guide\n- database_config.json.example - Configuration template\n\n**Files Modified:**\n- README.md - Added database setup section\n- requirements.txt - Added psycopg2-binary>=2.9.9\n\n**Documentation Includes:**\n\n1. **DATABASE_SETUP.md:**\n   - PostgreSQL installation (local/Docker)\n   - Database creation steps\n   - User and privileges setup\n   - Migration execution\n   - Connection troubleshooting\n   - Configuration examples\n   - Environment variable overrides\n\n2. **database_config.json.example:**\n   - Local configuration template\n   - Production configuration template\n   - Password placeholder support\n   - Connection pooling settings\n\n3. **README.md Updates:**\n   - Database setup section\n   - Quick start with database\n   - Configuration file examples\n   - CLI argument documentation\n\n**Verification:**\n- Documentation reviewed and complete\n- Examples tested and working\n- All configuration templates validated",
        "testStrategy": "Manual review: Documentation completeness\nExample validation: All code examples tested",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-11-30T03:24:13.463Z"
      },
      {
        "id": "11",
        "title": "Task 21: Redis Configuration and Infrastructure",
        "description": "Implement foundational Redis infrastructure with connection pooling, retry logic, and fallback mechanisms",
        "details": "**Status:** ‚úÖ Complete\n\n**Objective:** Establish Redis infrastructure for distributed coordination in HA system\n\n**Files Created:**\n- redis_config.json.example - Configuration template\n- core/config_loader.py - Configuration loader with env overrides\n- core/redis_coordinator.py - Redis coordinator with connection pooling\n- tests/unit/test_config_loader.py - 18 unit tests\n- tests/unit/test_redis_coordinator.py - 18 unit tests\n\n**Key Features Implemented:**\n\n1. **Redis Configuration Management:**\n   - Environment variable support (REDIS_HOST, REDIS_PORT, etc.)\n   - Password placeholder support (${REDIS_PASSWORD})\n   - Automatic type conversion for overrides\n   - Fallback to local environment\n\n2. **RedisCoordinator Class:**\n   - Connection pooling (redis.ConnectionPool, 50 connections)\n   - Retry logic with exponential backoff (0.5s, 1s, 2s)\n   - Fallback mode (database-only when Redis unavailable)\n   - Health checking via ping() with retry\n   - Context manager support\n\n3. **Configuration Loader:**\n   - load_config_file() - Load JSON config\n   - apply_env_overrides() - Apply environment variables\n   - load_redis_config() - Redis config with overrides\n   - load_database_config() - Database config with overrides\n\n**Test Results:**\n- ‚úÖ 36 tests passing (18 config + 18 coordinator)\n- ‚úÖ 71% code coverage for redis_coordinator.py\n- ‚úÖ No linter errors\n- ‚úÖ Full type hints\n\n**Integration Points:**\n- Ready for Task 22 (Leader Election)\n- Ready for Task 23 (Distributed Locking)\n- Ready for Task 25 (Signal Deduplication)\n\n**Verification:**\n```bash\npytest tests/unit/test_config_loader.py -v\npytest tests/unit/test_redis_coordinator.py -v\n```\n\n**Documentation:** TASK21_IMPLEMENTATION_SUMMARY.md (280+ lines)",
        "testStrategy": "Unit tests: 36 tests covering config loading, connection pooling, retry logic, fallback mode\nManual testing: Redis connectivity verification with ping()",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-11-30T03:24:47.673Z"
      },
      {
        "id": "12",
        "title": "Task 22: RedisCoordinator Leader Election",
        "description": "Implement atomic leader election primitives for distributed coordination",
        "details": "**Status:** ‚úÖ Complete\n\n**Objective:** Implement leader election mechanism using Redis atomic operations\n\n**Files Modified:**\n- core/redis_coordinator.py - Added leader election methods\n\n**Methods Implemented:**\n\n1. **try_become_leader() -> bool**\n   - Atomic SETNX with TTL (10 seconds)\n   - Sets leader key to instance ID\n   - Updates is_leader flag on success\n\n2. **renew_leadership() -> bool**\n   - Lua script for atomic get-and-set\n   - Verifies ownership before renewal\n   - Auto-detects leadership loss\n\n3. **get_current_leader() -> Optional[str]**\n   - Returns current leader instance ID\n   - Returns None if no leader exists\n\n4. **release_leadership() -> bool**\n   - Lua script for atomic delete\n   - Verifies ownership before release\n   - Updates is_leader flag\n\n**Instance ID Enhancement:**\n- Changed format from UUID to UUID-PID (e.g., \"550e8400-...-12345\")\n- Supports multiple concurrent instances on same host\n- Fixed critical bug in UUID parsing (dash counting)\n- Backward compatible with existing UUIDs\n\n**Lua Scripts:**\n- Renewal script: Atomic expire with ownership check\n- Release script: Atomic delete with ownership check\n\n**Test Coverage:**\n- 12 unit tests for leader election primitives\n- 5 tests for instance ID management\n- All tests passing ‚úÖ\n\n**Key Features:**\n- Atomic operations (no race conditions)\n- Automatic expiration (10s TTL)\n- Leadership loss detection\n- Graceful error handling\n- Fallback mode support\n\n**Verification:**\n```bash\npytest tests/unit/test_redis_coordinator.py::TestRedisCoordinatorLeaderElection -v\n```\n\n**Documentation:** TASK22_IMPLEMENTATION_SUMMARY.md (200+ lines)",
        "testStrategy": "Unit tests: 17 tests covering leader election, instance ID, atomic operations\nIntegration tests: Multi-instance leader election verification",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-11-30T03:24:47.897Z"
      },
      {
        "id": "13",
        "title": "Task 22.11: Stale Leader Detection",
        "description": "Detect crashed or network-partitioned leaders to prevent split-brain scenarios",
        "details": "**Status:** ‚úÖ Complete\n\n**Objective:** Detect instances with stale heartbeats (>30 seconds) to identify crashed leaders\n\n**Files Modified:**\n- core/db_state_manager.py - Added 2 new methods\n- migrations/002_add_heartbeat_index.sql - New migration for performance\n\n**Methods Implemented:**\n\n1. **get_stale_instances(heartbeat_timeout: int = 30) -> List[dict]**\n   - Detects instances with heartbeats older than timeout\n   - Returns: instance_id, is_leader, last_heartbeat, seconds_stale\n   - Used for health monitoring and split-brain detection\n\n2. **get_current_leader_from_db() -> Optional[dict]**\n   - Returns most recent leader with fresh heartbeat (<30s)\n   - Used for split-brain detection comparison with Redis\n\n**Database Migration:**\n```sql\nCREATE INDEX IF NOT EXISTS idx_instance_metadata_heartbeat_leader\nON instance_metadata(last_heartbeat DESC, is_leader)\nWHERE is_leader = TRUE;\n```\n- Partial index for efficient stale leader queries\n- Optimizes get_current_leader_from_db() performance\n\n**Test Coverage:**\n- ‚úÖ 8 unit tests (test_db_state_manager.py)\n- ‚úÖ 1 integration test (test_redis_coordinator_integration.py)\n- All tests passing\n\n**Trading System Impact:**\n- Prevents duplicate signal execution (‚Çπ50L capital protection)\n- Detects leader failures within 30 seconds\n- Enables automatic failover\n\n**Verification:**\n```bash\npytest tests/unit/test_db_state_manager.py -k stale -v\npytest tests/integration/test_redis_coordinator_integration.py -k stale -v\n```",
        "testStrategy": "Unit tests: 8 tests covering stale detection, custom timeouts, multiple instances\nIntegration tests: Real PostgreSQL stale leader detection",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-11-30T03:25:37.924Z"
      },
      {
        "id": "14",
        "title": "Task 22.12: Split-Brain Detection + Auto-Demote",
        "description": "Detect when Redis and PostgreSQL report different leaders and automatically demote conflicting instance",
        "details": "**Status:** ‚úÖ Complete (Critical Bug Fixed)\n\n**Objective:** Detect and resolve split-brain scenarios where Redis and DB disagree on leader\n\n**Files Modified:**\n- core/redis_coordinator.py - Added split-brain detection and auto-demote\n\n**Methods Implemented:**\n\n1. **detect_split_brain() -> Optional[dict]**\n   - Compares Redis leader with DB leader\n   - Returns: {'redis_leader': ..., 'db_leader': ..., 'conflict': True/False}\n   - Returns None if no DB manager or no conflict\n\n2. **Heartbeat Loop Integration:**\n   - Split-brain check runs every 10 iterations (~50 seconds)\n   - Auto-demotes if DB reports different leader\n   - Critical protection for financial safety\n\n**Auto-Demote Logic:**\n```python\nif conflict.get('db_leader') and conflict.get('db_leader') != self.instance_id:\n    logger.critical(f\"üö® Self-demoting due to split-brain...\")\n    self.release_leadership()  # Release Redis lock FIRST\n    self.is_leader = False      # Then step down\n```\n\n**Critical Bug Fixed:**\n- **Issue:** Was setting is_leader=False BEFORE release_leadership(), causing early return\n- **Fix:** Call release_leadership() first (which sets is_leader=False internally), then explicitly set flag\n- **Impact:** Auto-demote now works correctly, prevents duplicate signal execution\n\n**Test Coverage:**\n- ‚úÖ 7 unit tests (conflict detection, auto-demote)\n- ‚úÖ 3 integration tests (real Redis + PostgreSQL)\n- All tests passing\n\n**Financial Safety:**\n- Prevents duplicate signal execution (2x position size = 2x risk)\n- Auto-resolves split-brain within ~50 seconds\n- No manual intervention required\n\n**Verification:**\n```bash\npytest tests/unit/test_redis_coordinator.py -k split_brain -v\npytest tests/integration/test_redis_coordinator_integration.py -k split_brain -v\n```",
        "testStrategy": "Unit tests: 7 tests covering conflict detection, auto-demote, error handling\nIntegration tests: Real split-brain scenarios with Redis + PostgreSQL",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-11-30T03:25:38.170Z"
      },
      {
        "id": "15",
        "title": "Task 22.13: Leader Verification in Signal Processing",
        "description": "Ensure only the leader instance processes trading signals to prevent duplicate execution",
        "details": "**Status:** ‚úÖ Complete\n\n**Objective:** Add leader checks in webhook endpoint to prevent duplicate signal execution\n\n**Files Modified:**\n- portfolio_manager.py - Webhook endpoint with leader checks\n- live/engine.py - Optional leader check in process_signal()\n\n**Signal Processing Pipeline:**\n```\n1. Receive webhook signal\n2. Parse signal\n3. ‚úÖ Initial leadership check (Step 3.5) ‚Üê NEW\n4. Check duplicates\n5. ‚úÖ Re-check leadership (Step 4.5) ‚Üê NEW (Race condition protection)\n6. Process signal\n7. Return result\n```\n\n**Leader Checks:**\n\n1. **Initial Check (Step 3.5):**\n   - Before any signal processing\n   - Returns 200 OK with status='rejected', reason='not_leader'\n   - Prevents webhook retries\n\n2. **Re-check After Duplicate Detection (Step 4.5):**\n   - Protects against race conditions\n   - Returns 200 OK with reason='lost_leadership'\n   - Ensures leadership held throughout processing\n\n**Coordinator Integration:**\n- Added coordinator initialization with db_manager and redis_config\n- Added coordinator.start_heartbeat() for lifecycle management\n- Added coordinator.close() for graceful shutdown\n\n**Financial Safety:**\n- Prevents duplicate signal execution (‚Çπ1L per position risk)\n- Race condition protection (leadership can change during processing)\n- Graceful rejection (200 OK prevents webhook retries)\n\n**Test Coverage:**\n- ‚úÖ Integration tests verify leader checks work correctly\n- ‚úÖ Non-leader instances reject signals\n- ‚úÖ Leadership loss during processing aborts signal\n\n**Verification:**\n- Manual testing: Multi-instance webhook processing\n- Integration tests: Leader/follower signal rejection",
        "testStrategy": "Integration tests: Multi-instance webhook processing verification\nManual testing: Leader/follower signal rejection scenarios",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-11-30T03:25:38.420Z"
      },
      {
        "id": "16",
        "title": "Task 22.14: Observability/Metrics",
        "description": "Track critical HA metrics for monitoring and alerting",
        "details": "**Status:** ‚úÖ Complete\n\n**Objective:** Expose comprehensive metrics for HA system monitoring\n\n**Files Modified:**\n- core/redis_coordinator.py - Added CoordinatorMetrics class\n\n**CoordinatorMetrics Class:**\n```python\nclass CoordinatorMetrics:\n    - db_sync_success_count: int\n    - db_sync_failure_count: int\n    - db_sync_latency_ms: deque(maxlen=100)  # Rolling window\n    - leadership_changes: int\n    - last_heartbeat_time: Optional[datetime]\n```\n\n**Metrics Recording:**\n- _sync_leader_status_to_db(): Records DB sync success/failure and latency\n- _update_heartbeat_in_db(): Records DB sync success/failure and latency\n- is_leader setter: Records leadership changes\n- get_metrics(): Exposes comprehensive metrics snapshot\n\n**Metrics Exposed:**\n```python\n{\n    'db_sync_success': int,\n    'db_sync_failure': int,\n    'db_sync_failure_rate': float,  # failure_count / total_syncs\n    'db_sync_avg_latency_ms': float,  # Rolling window average\n    'leadership_changes': int,\n    'last_heartbeat': str,  # ISO format\n    'current_leader_redis': str | None,\n    'current_leader_db': str | None,\n    'this_instance': str,\n    'is_leader': bool,\n    'heartbeat_running': bool\n}\n```\n\n**Integration:**\n- Metrics accessible via coordinator.get_metrics()\n- Ready for Prometheus/StatsD export\n- Ready for Grafana dashboard integration\n\n**Monitoring Use Cases:**\n- Alert on high DB sync failure rate (>5%)\n- Alert on leadership changes (>3 per hour indicates instability)\n- Track DB sync latency (target <50ms p95)\n- Monitor heartbeat health\n\n**Verification:**\n```python\nmetrics = coordinator.get_metrics()\nprint(f\"DB Sync Failure Rate: {metrics['db_sync_failure_rate']:.2%}\")\nprint(f\"Leadership Changes: {metrics['leadership_changes']}\")\n```",
        "testStrategy": "Unit tests: Metrics collection and calculation verification\nManual testing: Metrics endpoint integration",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-11-30T03:26:24.664Z"
      },
      {
        "id": "17",
        "title": "Task 22.15: Leadership Log Levels",
        "description": "Elevate log levels for critical leadership events with visual markers",
        "details": "**Status:** ‚úÖ Complete\n\n**Objective:** Make critical leadership events highly visible in logs for rapid troubleshooting\n\n**Files Modified:**\n- core/redis_coordinator.py - Updated log levels for leadership events\n\n**Log Level Changes:**\n\n1. **Leadership Acquisition:**\n   - Level: INFO ‚Üí ERROR (with üéØ marker)\n   - Example: \"üéØ [instance-123] Became LEADER\"\n   - Rationale: Critical event requiring visibility\n\n2. **Leadership Loss:**\n   - Level: WARNING ‚Üí CRITICAL (with üö® marker)\n   - Example: \"üö® [instance-123] Lost leadership\"\n   - Rationale: Unexpected event requiring investigation\n\n3. **Split-Brain Detection:**\n   - Level: ERROR ‚Üí CRITICAL (with üö® marker)\n   - Example: \"üö® [instance-123] SPLIT-BRAIN DETECTED: Redis says X, DB says Y\"\n   - Rationale: Financial safety issue requiring immediate attention\n\n4. **Auto-Demote:**\n   - Level: WARNING ‚Üí CRITICAL (with üö® marker)\n   - Example: \"üö® [instance-123] Self-demoting due to split-brain...\"\n   - Rationale: Automatic remediation action requiring awareness\n\n**Visual Markers:**\n- üéØ Leadership acquired (positive event)\n- üö® Critical issues (loss, split-brain, auto-demote)\n- ‚ö†Ô∏è  Warnings (stale heartbeat, DB sync failures)\n\n**Benefits:**\n- Critical events visible in log aggregators (Datadog, CloudWatch)\n- Easier troubleshooting during incidents\n- Automated alerting on ERROR/CRITICAL levels\n- Clear visual distinction in terminal output\n\n**Verification:**\n```bash\n# Start instance and watch logs\npython portfolio_manager.py live --redis-config redis.json | grep -E \"üéØ|üö®\"\n```",
        "testStrategy": "Manual testing: Log output verification with visual markers\nIntegration tests: Log level verification in tests",
        "status": "done",
        "dependencies": [],
        "priority": "low",
        "subtasks": [],
        "updatedAt": "2025-11-30T03:26:24.917Z"
      },
      {
        "id": "18",
        "title": "Task 22.16: Leadership History/Audit Trail",
        "description": "Track all leadership transitions in PostgreSQL for audit and debugging",
        "details": "**Status:** ‚úÖ Complete\n\n**Objective:** Maintain complete audit trail of leadership changes for debugging and compliance\n\n**Files Created:**\n- migrations/003_add_leadership_history.sql - New migration\n\n**Database Schema:**\n```sql\nCREATE TABLE leadership_history (\n    id BIGSERIAL PRIMARY KEY,\n    instance_id VARCHAR(50) NOT NULL,\n    event_type VARCHAR(20) NOT NULL,  -- 'acquired', 'renewed', 'lost', 'released'\n    previous_leader VARCHAR(50),\n    timestamp TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    metadata JSONB,\n    INDEX idx_leadership_history_timestamp (timestamp DESC),\n    INDEX idx_leadership_history_instance (instance_id, timestamp DESC)\n);\n```\n\n**Files Modified:**\n- core/db_state_manager.py - Added record_leadership_transition() method\n\n**Method Implemented:**\n```python\ndef record_leadership_transition(\n    instance_id: str,\n    event_type: str,  # acquired, renewed, lost, released\n    previous_leader: Optional[str] = None,\n    metadata: Optional[dict] = None\n) -> bool\n```\n\n**Automatic Recording:**\n- Leadership acquisition: Recorded in try_become_leader()\n- Leadership loss: Recorded when leadership lost\n- Auto-demote: Recorded with split-brain metadata\n- Graceful release: Recorded in release_leadership()\n\n**Metadata Examples:**\n```python\n# Split-brain auto-demote\n{'reason': 'split_brain', 'redis_leader': 'X', 'db_leader': 'Y'}\n\n# Leadership renewal failure\n{'reason': 'renewal_failed', 'last_renewal': '2025-11-30T10:00:00'}\n```\n\n**Query Examples:**\n```sql\n-- Get all leadership changes in last 24 hours\nSELECT * FROM leadership_history \nWHERE timestamp > NOW() - INTERVAL '24 hours'\nORDER BY timestamp DESC;\n\n-- Count leadership changes per instance\nSELECT instance_id, COUNT(*) as changes\nFROM leadership_history\nWHERE event_type = 'acquired'\nGROUP BY instance_id;\n```\n\n**Benefits:**\n- Complete audit trail for compliance\n- Debug leadership instability issues\n- Identify problem instances\n- Track split-brain occurrences\n\n**Verification:**\n```bash\npsql -U pm_user -d portfolio_manager -c \"SELECT * FROM leadership_history ORDER BY timestamp DESC LIMIT 10;\"\n```",
        "testStrategy": "Integration tests: Leadership transition recording verification\nManual testing: Database audit trail inspection",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-11-30T03:26:25.180Z"
      },
      {
        "id": "19",
        "title": "Task 23: Implement Distributed Signal Locking",
        "description": "Implement distributed locking to prevent duplicate signal processing across concurrent instances",
        "details": "**Status:** Pending\n\n**Implementation Plan:**\n\n1. **In `RedisCoordinator`, implement locking methods:**\n   - `acquire_signal_lock(fingerprint, ttl=30)` ‚Üí bool\n   - `release_signal_lock(fingerprint)` ‚Üí bool\n\n2. **Use Redis atomic operations:**\n   - `SET key value NX EX 30` for atomic lock acquisition with TTL\n   - Key format: `signal_lock:{fingerprint}`\n   - Value: instance_id\n\n3. **Implement fallback mechanism:**\n   - If Redis is down, log error and default to database-level deduplication\n   - Graceful degradation ensures system continues operating\n\n4. **Error handling:**\n   - Handle Redis connection failures\n   - Log lock acquisition failures\n   - Ensure locks auto-expire after 30 seconds\n\n5. **Test coverage:**\n   - Unit tests for acquire/release\n   - Integration tests with Redis\n   - Fallback mode tests\n\n**Financial Safety:**\n- Prevents duplicate signal execution (‚Çπ1L per position risk)\n- Lock TTL ensures recovery from crashed instances\n- Fallback to database ensures no trading halt\n\n**Dependencies:**\n- Task 11 (Redis Infrastructure) must be complete",
        "testStrategy": "",
        "status": "pending",
        "dependencies": [
          "11"
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": "20",
        "title": "Task 24: Implement Signal Fingerprinting Logic",
        "description": "Create a standardized fingerprinting mechanism to uniquely identify signals for deduplication",
        "details": "**Status:** Pending\n\n**Implementation Plan:**\n\n1. **Create `core/fingerprint.py`:**\n   ```python\n   def generate_fingerprint(signal_data: dict) -> str:\n       # Concatenate instrument, signal_type, position_id, normalized timestamp\n       # Return SHA-256 hash\n   ```\n\n2. **Fingerprint components:**\n   - `instrument` (e.g., \"BANKNIFTY\")\n   - `signal_type` (e.g., \"BASE_ENTRY\", \"PYRAMID\", \"EXIT\")\n   - `position_id` (optional for BASE_ENTRY)\n   - Normalized `timestamp` (to second precision)\n\n3. **Timestamp normalization:**\n   - Round to nearest second\n   - Handle timezone differences\n   - Use ISO 8601 format\n\n4. **Hash generation:**\n   - Use SHA-256 for collision resistance\n   - Return hex digest (64 characters)\n\n5. **Edge cases:**\n   - Handle missing position_id (BASE_ENTRY signals)\n   - Handle malformed timestamps\n   - Handle special characters in instrument names\n\n6. **Test coverage:**\n   - Unit tests for hash stability (same input ‚Üí same hash)\n   - Tests for different signal types\n   - Tests for timestamp normalization\n   - Collision resistance tests\n\n**Example:**\n```python\nsignal = {\n    'instrument': 'BANKNIFTY',\n    'signal_type': 'BASE_ENTRY',\n    'timestamp': '2025-11-30T10:15:32.123Z'\n}\nfingerprint = generate_fingerprint(signal)\n# ‚Üí 'a1b2c3d4...' (SHA-256 hash)\n```",
        "testStrategy": "",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": "21",
        "title": "Task 25: Implement 3-Layer Signal Deduplication",
        "description": "Implement the core logic to check for duplicates at Memory, Redis, and Database levels",
        "details": "**Status:** Pending\n\n**Implementation Plan:**\n\n1. **Create `core/deduplication.py` with DeduplicationManager class:**\n\n2. **Layer 1: In-Memory Cache (LRU)**\n   - Use `functools.lru_cache` or `collections.OrderedDict`\n   - Cache last 1000 fingerprints\n   - O(1) lookup performance\n   - Resets on application restart\n\n3. **Layer 2: Redis Distributed Lock**\n   - Call `RedisCoordinator.acquire_signal_lock(fingerprint, ttl=30)`\n   - If lock acquired, signal is unique across all instances\n   - If lock fails, signal is duplicate or Redis is down\n   - Auto-expires after 30 seconds\n\n4. **Layer 3: PostgreSQL Deduplication**\n   - Query `signal_log` table for fingerprint\n   - Insert with UNIQUE constraint on fingerprint\n   - Handle `IntegrityError` as duplicate detection\n   - Permanent record for auditing\n\n5. **Integration logic:**\n   ```python\n   def is_duplicate(fingerprint: str) -> bool:\n       # Layer 1: Memory\n       if fingerprint in memory_cache:\n           return True\n       \n       # Layer 2: Redis\n       if not redis_coordinator.acquire_signal_lock(fingerprint):\n           return True\n       \n       # Layer 3: Database\n       if db_manager.check_duplicate_signal(fingerprint):\n           redis_coordinator.release_signal_lock(fingerprint)\n           return True\n       \n       # Not duplicate - add to memory cache\n       memory_cache.add(fingerprint)\n       return False\n   ```\n\n6. **Error handling:**\n   - Redis unavailable: Skip Layer 2, rely on Layer 3\n   - Database unavailable: HALT (cannot guarantee deduplication)\n   - Lock release failure: Log warning (TTL ensures cleanup)\n\n7. **Test coverage:**\n   - Unit tests for each layer\n   - Integration tests with all layers\n   - Fallback mode tests (Redis down)\n   - Race condition tests (concurrent signals)\n\n**Financial Safety:**\n- Triple redundancy prevents duplicate execution\n- Database layer is authoritative source of truth\n- Halts on database failure (safe failure mode)\n\n**Dependencies:**\n- Task 19 (Distributed Signal Locking)\n- Task 20 (Signal Fingerprinting)",
        "testStrategy": "",
        "status": "pending",
        "dependencies": [
          "19",
          "20"
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": "22",
        "title": "Task 26: Integrate Coordination into Webhook Endpoint",
        "description": "Update the main application entry point to use the new Redis coordination and deduplication logic",
        "details": "**Status:** Pending\n\n**Implementation Plan:**\n\n1. **Initialize RedisCoordinator in `portfolio_manager.py`:**\n   ```python\n   # In run_live() function\n   redis_coordinator = RedisCoordinator(redis_config, db_manager)\n   dedup_manager = DeduplicationManager(redis_coordinator, db_manager)\n   ```\n\n2. **Update webhook handler (`/webhook` endpoint):**\n   ```python\n   @app.route('/webhook', methods=['POST'])\n   def webhook():\n       signal_data = request.get_json()\n       \n       # Step 1: Generate fingerprint\n       fingerprint = generate_fingerprint(signal_data)\n       \n       # Step 2: Check deduplication (3 layers)\n       if dedup_manager.is_duplicate(fingerprint):\n           logger.warning(f\"Duplicate signal rejected: {fingerprint}\")\n           return jsonify({'status': 'duplicate', 'fingerprint': fingerprint}), 200\n       \n       try:\n           # Step 3: Process signal\n           result = engine.process_signal(signal_data)\n           \n           # Step 4: Log as processed\n           db_manager.log_signal(fingerprint, signal_data, status='processed')\n           \n           return jsonify({'status': 'success', 'result': result}), 200\n       \n       except Exception as e:\n           # Log as failed\n           db_manager.log_signal(fingerprint, signal_data, status='failed', error=str(e))\n           raise\n       \n       finally:\n           # Step 5: Release Redis lock\n           redis_coordinator.release_signal_lock(fingerprint)\n   ```\n\n3. **Update signal_log table:**\n   - Add `status` column ('pending', 'processed', 'failed')\n   - Add `error` column for failure details\n   - Add `processed_at` timestamp\n\n4. **Error handling:**\n   - Ensure lock is always released (finally block)\n   - Log all failures with context\n   - Return 200 OK for duplicates (prevent retries)\n\n5. **Monitoring:**\n   - Log duplicate count (warn if >5% of signals)\n   - Track lock acquisition failures\n   - Track processing time\n\n6. **Test coverage:**\n   - Integration test: Full webhook flow\n   - Test: Duplicate signal rejection\n   - Test: Lock release on error\n   - Test: Redis unavailable fallback\n   - Test: Database unavailable halt\n\n**Financial Safety:**\n- Deduplication prevents double execution\n- Lock ensures single processing\n- Database log provides audit trail\n\n**Dependencies:**\n- Task 21 (3-Layer Deduplication)",
        "testStrategy": "",
        "status": "pending",
        "dependencies": [
          "21"
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": "23",
        "title": "Task 28: Implement Statistics Persistence",
        "description": "Enable persistence of trading statistics for analytics and recovery",
        "details": "**Status:** Pending\n\n**Implementation Plan:**\n\n1. **Create database migration:**\n   ```sql\n   -- migrations/004_add_trading_statistics.sql\n   ALTER TABLE portfolio_state ADD COLUMN IF NOT EXISTS stats JSONB;\n   \n   CREATE INDEX IF NOT EXISTS idx_portfolio_state_stats \n   ON portfolio_state USING gin(stats);\n   ```\n\n2. **Statistics to persist:**\n   ```python\n   stats = {\n       'total_trades': int,\n       'winning_trades': int,\n       'losing_trades': int,\n       'total_pnl': Decimal,\n       'max_drawdown': Decimal,\n       'win_rate': float,\n       'profit_factor': float,\n       'avg_win': Decimal,\n       'avg_loss': Decimal,\n       'largest_win': Decimal,\n       'largest_loss': Decimal,\n       'consecutive_wins': int,\n       'consecutive_losses': int,\n       'max_consecutive_wins': int,\n       'max_consecutive_losses': int\n   }\n   ```\n\n3. **Update `DatabaseStateManager`:**\n   - Add `save_statistics(stats: dict) -> bool`\n   - Add `get_statistics() -> dict`\n   - Use JSONB column for flexible schema\n\n4. **Update `PortfolioStateManager`:**\n   - Track statistics in memory\n   - Update statistics on position close\n   - Persist to database via `db_manager.save_statistics()`\n\n5. **Recovery integration:**\n   - Load statistics on startup (CrashRecoveryManager)\n   - Verify consistency with positions\n\n6. **Reporting:**\n   - Add `/stats` endpoint to expose statistics\n   - Add daily rollover stats snapshot\n\n7. **Test coverage:**\n   - Unit tests for statistics calculation\n   - Integration tests for persistence\n   - Recovery tests (load stats after crash)\n\n**Benefits:**\n- Analytics and performance tracking\n- Recover statistics after crash\n- Historical performance analysis\n- Monitoring dashboard integration\n\n**Dependencies:**\n- Task 1 (CrashRecoveryManager) for loading stats on startup",
        "testStrategy": "",
        "status": "pending",
        "dependencies": [
          "1"
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": "24",
        "title": "Task 29: Implement Graceful Shutdown Mechanism",
        "description": "Ensure the application shuts down cleanly, releasing resources and locks",
        "details": "**Status:** Pending\n\n**Implementation Plan:**\n\n1. **Register signal handlers in `portfolio_manager.py`:**\n   ```python\n   import signal\n   \n   shutdown_flag = False\n   \n   def shutdown_handler(signum, frame):\n       global shutdown_flag\n       logger.info(\"Shutdown signal received - initiating graceful shutdown\")\n       shutdown_flag = True\n   \n   signal.signal(signal.SIGINT, shutdown_handler)   # Ctrl+C\n   signal.signal(signal.SIGTERM, shutdown_handler)  # Docker/K8s shutdown\n   ```\n\n2. **Update webhook handler:**\n   ```python\n   @app.route('/webhook', methods=['POST'])\n   def webhook():\n       if shutdown_flag:\n           return jsonify({'status': 'shutting_down'}), 503  # Service Unavailable\n       \n       # Normal processing...\n   ```\n\n3. **Shutdown sequence:**\n   ```python\n   def graceful_shutdown():\n       logger.info(\"Starting graceful shutdown sequence...\")\n       \n       # 1. Stop accepting new webhooks (done via shutdown_flag)\n       \n       # 2. Wait for pending signals to complete (max 30 seconds)\n       timeout = 30\n       start = time.time()\n       while redis_coordinator.has_pending_signals() and (time.time() - start) < timeout:\n           time.sleep(0.5)\n       \n       # 3. Release leadership (if leader)\n       if redis_coordinator.is_leader:\n           redis_coordinator.release_leadership()\n       \n       # 4. Release all signal locks\n       redis_coordinator.release_all_signal_locks()\n       \n       # 5. Close database connections\n       db_manager.close()\n       \n       # 6. Close Redis connections\n       redis_coordinator.close()\n       \n       logger.info(\"Graceful shutdown complete\")\n   ```\n\n4. **Add cleanup methods:**\n   - `RedisCoordinator.release_all_signal_locks()`: Release all locks held by this instance\n   - `RedisCoordinator.has_pending_signals()`: Check if any locks are held\n   - `DatabaseStateManager.close()`: Close connection pool\n\n5. **Health endpoint integration:**\n   - `/health` returns 503 when shutdown_flag is True\n   - Load balancer removes instance from rotation\n\n6. **Test coverage:**\n   - Unit tests for signal handlers\n   - Integration tests for shutdown sequence\n   - Test: Pending signals complete before shutdown\n   - Test: Leadership released\n   - Test: Locks released\n   - Test: Connections closed\n\n**Benefits:**\n- No interrupted signal processing\n- Clean leadership transfer\n- No orphaned locks\n- Database connection cleanup\n- Load balancer integration\n\n**Dependencies:**\n- Task 22 (Webhook Coordination Integration) for signal lock management",
        "testStrategy": "",
        "status": "pending",
        "dependencies": [
          "22"
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": "25",
        "title": "Task 30: Implement Health and Readiness Endpoints",
        "description": "Add endpoints for load balancer health checks and deployment readiness",
        "details": "**Status:** Pending\n\n**Implementation Plan:**\n\n1. **Create `endpoints/health.py`:**\n\n2. **Health endpoint (`GET /health`):**\n   ```python\n   @app.route('/health', methods=['GET'])\n   def health():\n       # Check connectivity\n       checks = {\n           'database': check_database_connection(),\n           'redis': check_redis_connection(),\n           'status': 'healthy' if all else 'unhealthy'\n       }\n       \n       status_code = 200 if checks['status'] == 'healthy' else 503\n       return jsonify(checks), status_code\n   \n   def check_database_connection() -> bool:\n       try:\n           db_manager.ping()  # Simple SELECT 1\n           return True\n       except Exception:\n           return False\n   \n   def check_redis_connection() -> bool:\n       try:\n           redis_coordinator.ping()\n           return True\n       except Exception:\n           return False\n   ```\n\n3. **Readiness endpoint (`GET /ready`):**\n   ```python\n   @app.route('/ready', methods=['GET'])\n   def ready():\n       # Check if application is ready to accept traffic\n       checks = {\n           'database': check_database_connection(),\n           'redis': check_redis_connection(),\n           'recovery_complete': recovery_manager.is_recovery_complete(),\n           'shutdown_flag': not shutdown_flag,\n           'status': 'ready' if all else 'not_ready'\n       }\n       \n       status_code = 200 if checks['status'] == 'ready' else 503\n       return jsonify(checks), status_code\n   ```\n\n4. **Add recovery completion tracking:**\n   ```python\n   # In CrashRecoveryManager\n   def is_recovery_complete(self) -> bool:\n       return self._recovery_complete\n   \n   # Set to True after successful load_state()\n   ```\n\n5. **Liveness endpoint (`GET /live`):**\n   ```python\n   @app.route('/live', methods=['GET'])\n   def liveness():\n       # Simple liveness check (process is running)\n       return jsonify({'status': 'alive'}), 200\n   ```\n\n6. **Integration with Kubernetes:**\n   ```yaml\n   # k8s deployment.yaml\n   livenessProbe:\n     httpGet:\n       path: /live\n       port: 5000\n     initialDelaySeconds: 10\n     periodSeconds: 5\n   \n   readinessProbe:\n     httpGet:\n       path: /ready\n       port: 5000\n     initialDelaySeconds: 30\n     periodSeconds: 10\n   ```\n\n7. **Test coverage:**\n   - Unit tests for health checks\n   - Integration tests with real dependencies\n   - Test: Database down\n   - Test: Redis down\n   - Test: Recovery incomplete\n   - Test: Shutdown flag set\n\n**Benefits:**\n- Load balancer health checks\n- Kubernetes liveness/readiness probes\n- Graceful deployment (wait for recovery)\n- Traffic routing based on health\n\n**Dependencies:**\n- Task 1 (CrashRecoveryManager) for recovery status\n- Task 24 (Graceful Shutdown) for shutdown flag",
        "testStrategy": "",
        "status": "pending",
        "dependencies": [
          "1",
          "24"
        ],
        "priority": "low",
        "subtasks": []
      },
      {
        "id": "26",
        "title": "Task 31: Fix DB Sync Race Condition in Leader Status Sync",
        "description": "Resolve critical race condition where leader status updates in database are not immediately visible to other connections",
        "details": "**Status:** ‚úÖ Complete\n\n**Objective:** Ensure strict consistency for split-brain detection by forcing fresh connections for critical reads\n\n**Problem Identified:**\n- PostgreSQL connection pooling can return stale connections\n- Leader status updates may not be visible immediately on other connections\n- Split-brain detection could read stale data\n- Race condition window: <100ms but critical for financial safety\n\n**Solution Implemented:**\n- Force fresh connections for split-brain detection reads\n- `get_current_leader_from_db()` closes and reopens connection\n- Guarantees read-after-write consistency\n- Eliminates need for polling/retry delays\n\n**Implementation:**\n```python\ndef get_current_leader_from_db(self) -> Optional[dict]:\n    # Close current connection (return to pool)\n    self._close_connection()\n    \n    # Get fresh connection (guaranteed latest data)\n    conn = self._get_connection()\n    \n    # Read leader status\n    # ...\n```\n\n**Benefits:**\n- Eliminates stale read race condition\n- No performance overhead on write path\n- Minimal overhead on read path (only for split-brain checks every ~50s)\n- Strict consistency for financial safety\n\n**Testing:**\n- ‚úÖ Unit tests verify fresh connection logic\n- ‚úÖ Integration tests verify split-brain detection accuracy\n- ‚úÖ No false positives in testing\n\n**Documentation:**\n- Detailed analysis in `CRITICAL_DB_SYNC_INVESTIGATION.md`\n- Fix details in `FIXPLAN_FEEDBACK.md`\n- Implementation verified in `PHASE1_CRITICAL_FIXES_SUMMARY.md`\n\n**Dependencies:**\n- Task 12 (Leader Election) required for baseline functionality\n- Integrated with Task 14 (Split-Brain Detection)",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          "12"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-11-30T05:01:32.936Z"
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2025-11-30T05:01:32.936Z",
      "taskCount": 26,
      "completedCount": 18,
      "tags": [
        "master"
      ]
    }
  }
}