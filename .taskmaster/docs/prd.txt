# Portfolio Manager High Availability System - Product Requirements Document

## ⚠️ PHASE 1 STATUS: ✅ COMPLETED

**Phase 1 (Database Schema + Basic Persistence) has been fully implemented and verified.**

### Phase 1 Completion Summary

**Status:** ✅ **COMPLETE** (Ready for Final Verification)  
**Date:** November 28, 2025  
**Branch:** `feature/ha-phase1-database-persistence`

#### Completed Tasks:
1. ✅ Updated Position Model - Added `is_base_position` field
2. ✅ Created Database Schema - All 5 PostgreSQL tables with indexes
3. ✅ Implemented DatabaseStateManager class - Full CRUD operations
4. ✅ Created Unit Tests - 20+ test cases for DatabaseStateManager
5. ✅ Integrated with PortfolioStateManager - Database hooks for closed_equity
6. ✅ Integrated with LiveTradingEngine - Persistence calls and state recovery
7. ✅ Updated Main Application - CLI arguments and database initialization
8. ✅ Created Integration Tests - 6+ test cases for end-to-end flow
9. ✅ Documentation - DATABASE_SETUP.md and configuration examples

#### Key Features Implemented:
- ✅ All positions persisted to PostgreSQL
- ✅ Portfolio state persisted (closed_equity, risk metrics)
- ✅ Pyramiding state persisted (last_pyramid_price, base_position_id)
- ✅ Signal logging for audit trail
- ✅ State recovery on startup (load all open positions, pyramiding state, portfolio state)
- ✅ Connection pooling with retry logic
- ✅ Write-through caching (L1 cache)
- ✅ Optimistic locking (version field)

#### Files Created:
- `core/db_state_manager.py` (500+ lines)
- `migrations/001_initial_schema.sql` (200+ lines)
- `tests/unit/test_db_state_manager.py` (400+ lines, 20+ tests)
- `tests/integration/test_persistence.py` (300+ lines, 6+ tests)
- `DATABASE_SETUP.md` (400+ lines)
- `database_config.json.example`

#### Files Modified:
- `core/models.py` - Added `is_base_position` field
- `core/portfolio_state.py` - Database hooks
- `live/engine.py` - Persistence calls and state recovery
- `portfolio_manager.py` - Database initialization

#### Implementation Statistics:
- **Lines of Code Added:** ~2,000+
- **Files Created:** 7
- **Files Modified:** 5
- **Test Cases:** 26+
- **Database Tables:** 5
- **Database Indexes:** 8

**Next Phase:** Phase 2 - Redis Coordination (Leader Election, Distributed Locking, Heartbeat System)

---

# Portfolio Manager High Availability System - State Persistence & Distributed Coordination

## Executive Summary

Implement production-grade state persistence and high availability for the Portfolio Manager using **PostgreSQL + Redis** to enable crash recovery, multi-instance deployment, and automatic failover.

**Architecture:**
- **PostgreSQL**: Persistent state storage with ACID transactions and row-level locking
- **Redis**: Distributed coordination, leader election, and signal-level locking
- **Active-Active**: **ALL instances process webhooks concurrently** (no leader needed for signals)
- **Leader Election**: ONLY for background tasks (rollover scheduler, cleanup)
- **Hybrid Deployment**: Local development + cloud production (AWS/Azure)

**Key Requirements:**
- ✅ Full crash recovery - restore all state from database on restart
- ✅ Zero-downtime failover - automatic takeover if instance crashes (<3 seconds)
- ✅ No duplicate signals - 3-layer deduplication (local cache, Redis, database)
- ✅ Transactional consistency - atomic signal processing with rollback on failure
- ✅ Distributed locking - prevent split-brain scenarios in active-active setup

---

## IMPORTANT: Active-Active Architecture Clarification

**Signal Processing:** ALL instances process webhooks concurrently
- Load balancer distributes webhooks across ALL running instances
- Each instance can process any signal (BASE_ENTRY, PYRAMID, EXIT)
- Redis distributed locks prevent duplicate processing
- **NO leader election needed for signal processing**

**Leader Election:** ONLY for background tasks
- **Rollover Scheduler:** Only leader runs rollover checks (hourly/daily)
- **Signal Log Cleanup:** Only leader runs cleanup job (delete old entries)
- **Orphaned Lock Cleanup:** Only leader runs periodic cleanup
- **Statistics Aggregation:** Only leader runs periodic aggregation

**Why this design?**
- **Scalability:** All instances handle traffic (not bottlenecked by single leader)
- **Resilience:** If leader dies, another becomes leader in <3 seconds (only background tasks pause briefly)
- **Simplicity:** No complex request routing - load balancer handles distribution

**Example scenario:**
```
Instance 1 (Leader):          Instance 2 (Follower):
✓ Processes webhooks          ✓ Processes webhooks
✓ Runs rollover at 9:00 AM    ✗ Skips rollover (not leader)
✓ Cleans signal_log daily     ✗ Skips cleanup (not leader)

If Instance 1 crashes:
Instance 2 becomes leader in <3s
✓ Continues processing webhooks (no interruption)
✓ Now runs rollover
✓ Now runs cleanup
```

---

## 1. Critical State Requiring Persistence

Based on comprehensive code analysis, the following state **must** be persisted to database:

### A. Position State (Core Trading Data)

**From:** `core/models.py` - Position dataclass

```python
Position {
  # Identification
  position_id: str              # Long_1, Long_2, etc.
  instrument: str               # BANK_NIFTY or GOLD_MINI
  status: str                   # open, closed, partial

  # Entry Data (immutable)
  entry_timestamp: datetime
  entry_price: float
  lots: int
  quantity: int

  # Stop Management (mutable - updated frequently)
  initial_stop: float           # Never changes
  current_stop: float           # Trailing stop - updates every bar
  highest_close: float          # High watermark for trailing calc

  # P&L Tracking (mutable)
  unrealized_pnl: float
  realized_pnl: float

  # Rollover Fields (Bank Nifty/Gold Mini)
  rollover_status: str          # none, pending, in_progress, rolled, failed
  original_expiry: str
  original_strike: int
  rollover_timestamp: datetime
  rollover_pnl: float
  rollover_count: int

  # Synthetic Futures (Bank Nifty)
  strike: int
  expiry: str
  pe_symbol: str
  ce_symbol: str
  pe_order_id: str
  ce_order_id: str
  pe_entry_price: float
  ce_entry_price: float

  # Futures (Gold Mini)
  contract_month: str
  futures_symbol: str
  futures_order_id: str

  # Metadata
  atr: float
  limiter: str
  risk_contribution: float
  vol_contribution: float
  is_base_position: bool        # TRUE for base entry, FALSE for pyramids
}
```

### B. Portfolio State

```python
PortfolioState {
  initial_capital: float        # Starting capital (₹50L)
  closed_equity: float          # Cash + realized P&L (CRITICAL)

  # Derived metrics (useful for recovery validation)
  total_risk_amount: float
  total_risk_percent: float
  total_vol_amount: float
  margin_used: float
}
```

### C. Pyramiding State

**From:** `live/engine.py` - in-memory dicts

```python
PyramidingState {
  instrument: str                   # BANK_NIFTY or GOLD_MINI
  last_pyramid_price: float         # Price of last pyramid
  base_position_id: str             # Reference to base position
}
```

### D. Signal Deduplication

**From:** `core/webhook_parser.py` - DuplicateDetector

```python
SignalFingerprint {
  instrument: str
  signal_type: str              # BASE_ENTRY, PYRAMID, EXIT
  position: str                 # Long_1, Long_2, etc.
  timestamp: datetime
  fingerprint: str              # Hash for uniqueness
  processed_at: datetime
}
```

### E. Instance Metadata (for HA)

```python
InstanceMetadata {
  instance_id: str              # UUID for this instance
  started_at: datetime
  last_heartbeat: datetime
  last_signal_processed: datetime
  is_leader: bool               # Redis-based leader election
  status: str                   # active, standby, crashed
}
```

---

## 2. Database Schema (PostgreSQL)

### Table 1: portfolio_positions

Primary table for all positions (open and closed).

```sql
CREATE TABLE portfolio_positions (
    -- Primary key
    position_id VARCHAR(50) PRIMARY KEY,

    -- Identification
    instrument VARCHAR(20) NOT NULL,
    status VARCHAR(20) NOT NULL DEFAULT 'open',  -- open, closed, partial

    -- Entry data (immutable)
    entry_timestamp TIMESTAMP NOT NULL,
    entry_price DECIMAL(12,2) NOT NULL,
    lots INTEGER NOT NULL,
    quantity INTEGER NOT NULL,

    -- Stop management (mutable)
    initial_stop DECIMAL(12,2) NOT NULL,
    current_stop DECIMAL(12,2) NOT NULL,
    highest_close DECIMAL(12,2) NOT NULL,

    -- P&L tracking (mutable)
    unrealized_pnl DECIMAL(15,2) DEFAULT 0.0,
    realized_pnl DECIMAL(15,2) DEFAULT 0.0,

    -- Rollover fields
    rollover_status VARCHAR(20) DEFAULT 'none',
    original_expiry VARCHAR(20),
    original_strike INTEGER,
    original_entry_price DECIMAL(12,2),
    rollover_timestamp TIMESTAMP,
    rollover_pnl DECIMAL(15,2) DEFAULT 0.0,
    rollover_count INTEGER DEFAULT 0,

    -- Synthetic futures (Bank Nifty)
    strike INTEGER,
    expiry VARCHAR(20),
    pe_symbol VARCHAR(50),
    ce_symbol VARCHAR(50),
    pe_order_id VARCHAR(50),
    ce_order_id VARCHAR(50),
    pe_entry_price DECIMAL(12,2),
    ce_entry_price DECIMAL(12,2),

    -- Futures (Gold Mini)
    contract_month VARCHAR(20),
    futures_symbol VARCHAR(50),
    futures_order_id VARCHAR(50),

    -- Metadata
    atr DECIMAL(12,2),
    limiter VARCHAR(50),
    risk_contribution DECIMAL(8,4),
    vol_contribution DECIMAL(8,4),
    is_base_position BOOLEAN DEFAULT FALSE,  -- TRUE for base entry, FALSE for pyramids

    -- Versioning for optimistic locking
    version INTEGER DEFAULT 1,

    -- Timestamps
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    -- Indexes
    INDEX idx_instrument_status (instrument, status),
    INDEX idx_status (status),
    INDEX idx_created_at (created_at),
    INDEX idx_instrument_entry (instrument, entry_timestamp),  -- For position queries by instrument
    INDEX idx_rollover_status (rollover_status, expiry)  -- For rollover queries
);
```

### Table 2: portfolio_state

Single-row table for portfolio-level state.

```sql
CREATE TABLE portfolio_state (
    id INTEGER PRIMARY KEY DEFAULT 1,
    initial_capital DECIMAL(15,2) NOT NULL,
    closed_equity DECIMAL(15,2) NOT NULL,

    -- Derived metrics (for validation)
    total_risk_amount DECIMAL(15,2),
    total_risk_percent DECIMAL(8,4),
    total_vol_amount DECIMAL(15,2),
    margin_used DECIMAL(15,2),

    -- Versioning
    version INTEGER DEFAULT 1,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    -- Ensure only one row
    CONSTRAINT single_row CHECK (id = 1)
);
```

### Table 3: pyramiding_state

Tracks pyramiding metadata per instrument.

```sql
CREATE TABLE pyramiding_state (
    instrument VARCHAR(20) PRIMARY KEY,
    last_pyramid_price DECIMAL(12,2),
    base_position_id VARCHAR(50) NULL,  -- Nullable: can be NULL if base position closed
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    -- Foreign key to positions (nullable to allow base position closure)
    FOREIGN KEY (base_position_id) REFERENCES portfolio_positions(position_id) ON DELETE SET NULL
);
```

### Table 4: signal_log

Deduplication and audit trail for all webhook signals.

```sql
CREATE TABLE signal_log (
    id BIGSERIAL PRIMARY KEY,

    -- Signal identification
    instrument VARCHAR(20) NOT NULL,
    signal_type VARCHAR(20) NOT NULL,
    position VARCHAR(20) NOT NULL,
    signal_timestamp TIMESTAMP NOT NULL,

    -- Deduplication
    fingerprint VARCHAR(64) UNIQUE NOT NULL,  -- Hash of (instrument, type, position, timestamp)
    is_duplicate BOOLEAN DEFAULT FALSE,

    -- Processing metadata
    processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    processed_by_instance VARCHAR(50),
    processing_status VARCHAR(20),  -- accepted, rejected, blocked, executed

    -- Full signal payload
    payload JSONB,

    -- Indexes
    INDEX idx_fingerprint (fingerprint),
    INDEX idx_processed_at (processed_at),  -- For cleanup queries
    INDEX idx_instrument_timestamp (instrument, signal_timestamp)
);

-- Cleanup function for old signal_log entries (keep only last 7 days)
CREATE OR REPLACE FUNCTION cleanup_old_signals() RETURNS void AS $$
BEGIN
    DELETE FROM signal_log WHERE processed_at < NOW() - INTERVAL '7 days';
END;
$$ LANGUAGE plpgsql;
```

### Table 5: instance_metadata

Tracks all running instances for health monitoring and leader election.

```sql
CREATE TABLE instance_metadata (
    instance_id VARCHAR(50) PRIMARY KEY,
    started_at TIMESTAMP NOT NULL,
    last_heartbeat TIMESTAMP NOT NULL,
    last_signal_processed TIMESTAMP,

    -- Leader election (Redis primary, database backup)
    is_leader BOOLEAN DEFAULT FALSE,
    leader_acquired_at TIMESTAMP,

    -- Health status
    status VARCHAR(20) NOT NULL,  -- active, standby, crashed

    -- Deployment info
    hostname VARCHAR(100),
    port INTEGER,
    version VARCHAR(20),

    -- Timestamps
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    -- Index for cleanup
    INDEX idx_last_heartbeat (last_heartbeat)
);
```

---

## 3. State Persistence Layer

### Class: DatabaseStateManager

**File:** `portfolio_manager/core/db_state_manager.py` (COMPLETED IN PHASE 1)

Handles all database operations with connection pooling, transactions, and caching.

Key features implemented:
- Connection pooling (psycopg2.pool)
- Transaction management with retry logic
- Write-through caching (L1 cache)
- Crash recovery support
- Optimistic locking (version field)

---

## 4. Redis Coordination Layer

### Class: RedisCoordinator

**File:** `portfolio_manager/core/redis_coordinator.py` (NEW - PHASE 2)

Handles distributed coordination, leader election, and signal-level locking.

Key features to implement:
- Leader election (SETNX with TTL)
- Heartbeat system
- Signal-level distributed locks
- Health monitoring

---

## 5. Crash Recovery Manager

### Class: CrashRecoveryManager

**File:** `portfolio_manager/live/recovery.py` (NEW - PHASE 4)

Handles startup recovery, orphaned lock cleanup, and state validation.

Key features to implement:
- Load state from database
- Clean orphaned locks
- Validate consistency
- Resume trading

---

## 6. Signal Fingerprint Calculation

**File:** `portfolio_manager/core/fingerprint.py` (NEW - PHASE 3)

Unique fingerprint calculation for signal deduplication across all 3 layers.

Uses SHA-256 hash of normalized signal data:
- Instrument (BANK_NIFTY, GOLD_MINI)
- Signal type (BASE_ENTRY, PYRAMID, EXIT)
- Position (Long_1, Long_2, etc.)
- Timestamp (normalized to second precision)

---

## 7. Broker Reconciliation

Add to `CrashRecoveryManager` class (PHASE 4)

Reconcile database positions with actual broker positions to detect:
1. Orphaned positions (in DB but not in broker)
2. Missing positions (in broker but not in DB)
3. Quantity mismatches

---

## 8. Statistics Persistence

**Option 1: JSONB Column in portfolio_state Table**

Add statistics column to portfolio_state table and persist trading stats.

**Option 2: Separate statistics Table** (better for analytics)

Create dedicated trading_statistics table for better query performance.

---

## 9. Health Check & Monitoring

**File:** `portfolio_manager/endpoints/health.py` (NEW - PHASE 6)

Provides instance health status for load balancer health checks:
- `/health` - Health check endpoint (200 OK if healthy, 503 if unhealthy)
- `/ready` - Readiness check (can instance accept traffic?)

---

## 10. Graceful Shutdown

Add to main `portfolio_manager.py` (PHASE 4)

Ensures clean shutdown on SIGTERM/SIGINT:
- Stop accepting new requests
- Wait for in-flight requests to complete
- Flush pending database writes
- Release Redis locks
- Close database connections

---

## 11. Database Connection Retry Logic

**COMPLETED IN PHASE 1**

DatabaseStateManager includes:
- Retry connection with exponential backoff
- Transaction retry on connection loss
- Graceful error handling

---

## 12. Redis Fallback to Database-Only Mode

Add to `RedisCoordinator.__init__()` (PHASE 2)

If Redis is unavailable, fallback to database-only mode:
- Single-instance mode (no distributed locking)
- Database-based deduplication only
- Graceful degradation

---

## 13. Transaction Isolation Levels

**Documentation:**

PostgreSQL uses `READ COMMITTED` isolation level by default, which is appropriate for most operations.

**Isolation Level Usage:**

| Operation | Isolation Level | Rationale |
|-----------|----------------|-----------|
| Signal processing (entry/exit) | `READ COMMITTED` | Sufficient - row-level locks prevent conflicts |
| Portfolio state updates | `READ COMMITTED` | Single-row table, atomic updates |
| Position updates (trailing stops) | `READ COMMITTED` | Optimistic locking (version field) handles conflicts |
| Rollover operations | `SERIALIZABLE` | Critical - prevents partial rollovers from concurrent operations |
| Signal deduplication check | `READ COMMITTED` | UNIQUE constraint provides serialization |

---

## 14. Implementation Phases

### Phase 1: Database Schema + Basic Persistence ✅ COMPLETED

**Status:** ✅ **COMPLETE**

**Tasks Completed:**
1. ✅ Create PostgreSQL schema (5 tables)
2. ✅ Implement DatabaseStateManager class
3. ✅ Integrate with PortfolioStateManager
4. ✅ Add save_position() calls in LiveTradingEngine
5. ✅ Test: Insert/update positions, load on startup

**Files Created:**
- `core/db_state_manager.py`
- `migrations/001_initial_schema.sql`
- `tests/unit/test_db_state_manager.py`
- `tests/integration/test_persistence.py`
- `DATABASE_SETUP.md`

**Files Modified:**
- `core/models.py` - Added `is_base_position` field
- `core/portfolio_state.py` - Database hooks
- `live/engine.py` - Persistence calls
- `portfolio_manager.py` - Database initialization

---

### Phase 2: Redis Coordination (Week 2)

**Tasks:**
1. Implement RedisCoordinator class
2. Add leader election logic
3. Implement heartbeat system
4. Add signal-level distributed locks
5. Test: Multiple instances, leader failover

**Files to Create:**
- NEW: `core/redis_coordinator.py`
- NEW: `redis_config.json.example`

**Files to Modify:**
- MODIFY: `portfolio_manager.py` - add Redis initialization
- MODIFY: `live/engine.py` - acquire lock before processing signal

**Testing:**
- Unit tests for RedisCoordinator
- Leader election test: Kill leader → verify new leader elected (<3 sec)
- Lock test: Two instances try to process same signal → only one succeeds

---

### Phase 3: Active-Active Coordination (Week 3)

**Tasks:**
1. 3-layer duplicate detection (local cache → Redis lock → database)
2. Modify webhook endpoint to acquire Redis lock
3. Add database fingerprint check
4. Add Nginx load balancer configuration
5. Test: Concurrent signal processing

**Files to Create:**
- NEW: `core/fingerprint.py`
- NEW: `nginx.conf` - load balancer config

**Files to Modify:**
- MODIFY: `portfolio_manager.py` - webhook endpoint with locking
- MODIFY: `core/webhook_parser.py` - add database dedup

**Testing:**
- Concurrent webhook test: Send 100 signals simultaneously → all processed exactly once
- Split-brain test: Network partition → verify no duplicates

---

### Phase 4: Crash Recovery (Week 4)

**Tasks:**
1. Implement CrashRecoveryManager
2. Add startup recovery sequence
3. Add orphaned lock cleanup
4. Add position validation
5. Test: Kill instance mid-signal → restart → resume

**Files to Create:**
- NEW: `live/recovery.py`

**Files to Modify:**
- MODIFY: `portfolio_manager.py` - call recovery on startup
- MODIFY: `portfolio_manager.py` - graceful shutdown handler

**Testing:**
- Crash during entry test: Kill after broker order → verify position recovered
- Crash during rollover test: Kill mid-rollover → verify partial state handled
- Graceful shutdown test: Stop instance → verify cleanup

---

### Phase 5: Integration Testing (Week 5)

**Tasks:**
1. End-to-end tests (100+ scenarios)
2. Chaos testing (random crashes)
3. Performance testing (1000 signals/min)
4. Load balancer testing
5. Rollover recovery testing

**Test Scenarios:**
- Happy path: BASE_ENTRY → PYRAMID → EXIT with 2 instances
- Crash scenario: Instance crashes during pyramid → other instance takes over
- Split-brain: Network partition → verify no duplicate entries
- Rollover: Partial rollover → crash → resume
- Performance: 1000 concurrent webhooks → verify latency <200ms (p95)

---

### Phase 6: Deployment (Week 6)

**Tasks:**
1. Docker Compose for local multi-instance deployment
2. AWS deployment (ALB + ECS + RDS + ElastiCache)
3. Health checks and monitoring
4. Alerting (PagerDuty/Slack)
5. Documentation

**Deployment Architecture:**
```
TradingView Webhooks
         ↓
AWS Application Load Balancer (ALB)
    ↓                    ↓
Portfolio Manager    Portfolio Manager
  Instance 1           Instance 2
  (ECS Task)          (ECS Task)
    ↓                    ↓
    ↓← Redis Leader Election →↓
      (ElastiCache Redis)
    ↓                    ↓
    ↓← PostgreSQL RDS →↓
      (Primary + Read Replica)
```

---

## Configuration

### database_config.json

```json
{
  "local": {
    "host": "localhost",
    "port": 5432,
    "database": "portfolio_manager",
    "user": "pm_user",
    "password": "dev_password",
    "minconn": 2,
    "maxconn": 10
  },
  "production": {
    "host": "portfolio-db.abc123.us-east-1.rds.amazonaws.com",
    "port": 5432,
    "database": "portfolio_manager_prod",
    "user": "pm_prod_user",
    "password": "${DB_PASSWORD}",
    "minconn": 5,
    "maxconn": 20
  }
}
```

### redis_config.json

```json
{
  "local": {
    "host": "localhost",
    "port": 6379,
    "db": 0,
    "password": null
  },
  "production": {
    "host": "portfolio-redis.abc123.use1.cache.amazonaws.com",
    "port": 6379,
    "db": 0,
    "password": "${REDIS_PASSWORD}",
    "ssl": true
  }
}
```

---

## Testing Strategy

### Unit Tests (50+ tests)

- `test_db_state_manager.py` - Database CRUD operations ✅ COMPLETED
- `test_redis_coordinator.py` - Leader election, locks, heartbeats (PHASE 2)
- `test_crash_recovery.py` - Recovery logic, validation (PHASE 4)

### Integration Tests (30+ tests)

- `test_persistence.py` - End-to-end signal → database → recovery ✅ COMPLETED
- `test_active_active.py` - Concurrent signal processing (PHASE 3)
- `test_failover.py` - Leader election, instance crash scenarios (PHASE 2)

### Chaos Tests (20+ tests)

- Random instance crashes during signal processing
- Network partitions (split-brain scenarios)
- Database connection failures
- Redis failures (fallback to database-only mode)

---

## Summary

This plan provides a **production-ready, highly available** Portfolio Manager with:

✅ **PostgreSQL persistence** - Full state recovery from database with optimistic locking (PHASE 1 COMPLETE)
⏳ **Redis coordination** - Fast leader election (<3 sec failover), 30s signal locks (PHASE 2)
⏳ **Active-active architecture** - ALL instances process webhooks (leader only for background tasks) (PHASE 3)
⏳ **Crash recovery** - Complete state restoration with broker reconciliation (PHASE 4)
⏳ **3-layer deduplication** - Local cache → Redis lock → Database constraint (SHA-256 fingerprints) (PHASE 3)
⏳ **Transactional consistency** - Atomic signal processing with rollback and retry logic (PHASE 1 COMPLETE)
⏳ **Graceful shutdown** - Clean SIGTERM/SIGINT handling with lock release (PHASE 4)
⏳ **Health monitoring** - /health and /ready endpoints for load balancers (PHASE 6)
⏳ **Error resilience** - Database retry logic (PHASE 1 COMPLETE), Redis fallback to DB-only mode (PHASE 2)
⏳ **Statistics persistence** - Trading stats stored in PostgreSQL JSONB/separate table (PHASE 2)
⏳ **Broker reconciliation** - Automatic position sync validation on startup (PHASE 4)
⏳ **Hybrid deployment** - Local dev + cloud production (AWS/Azure) (PHASE 6)

**Total Implementation:** 6 weeks
**Current Progress:** Phase 1 Complete (Week 1/6)
**Lines of Code:** ~2,000+ (Phase 1) + ~1,500 (remaining phases) + 1,500 (tests)
**Performance:** <200ms webhook latency (p95), 1000 signals/min throughput

**Key Improvements from Review:**
- ✅ Clarified active-active architecture (all instances process signals)
- ✅ Increased signal lock TTL from 5s to 30s
- ✅ Added `is_base_position` field to Position model (PHASE 1 COMPLETE)
- ✅ Made `base_position_id` nullable in pyramiding_state (PHASE 1 COMPLETE)
- ✅ Added fingerprint calculation (SHA-256) (PHASE 3)
- ✅ Added broker reconciliation method (PHASE 4)
- ✅ Added statistics persistence (JSONB + separate table options) (PHASE 2)
- ✅ Added health check endpoints (/health, /ready) (PHASE 6)
- ✅ Added graceful shutdown handler (PHASE 4)
- ✅ Added database connection retry with exponential backoff (PHASE 1 COMPLETE)
- ✅ Added Redis fallback mode (database-only) (PHASE 2)
- ✅ Added missing database indexes (5 total) (PHASE 1 COMPLETE)
- ✅ Documented transaction isolation levels (READ COMMITTED vs SERIALIZABLE)

---

**Last Updated:** November 28, 2025
**Phase 1 Status:** ✅ COMPLETE
**Next Phase:** Phase 2 - Redis Coordination

